{
 "cells": [
  {
   "source": [
    "Backlogg\n",
    "===\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "- test format of date\n",
    "- proper check for file not found\n",
    "- temporary definition of constants\n"
=======
    "- todo test format of date\n"
>>>>>>> many small improvements and more comments
=======
    "- test format of date\n",
    "- proper check for file not found\n",
    "- temporary definition of constants\n"
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 127,
   "metadata": {},
=======
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
>>>>>>> many small improvements and more comments
=======
   "execution_count": 127,
   "metadata": {},
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import BDay # BDay for business day\n",
    "\n",
    "#todo temporary definition of constants\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "def create_stock_df(nr_days_to_trade=500, start_date_str='2017-01-17', nr_days_of_history=10):\n",
=======
    "def create_stock_df(nr_days_to_trade=100, start_date_str='2017-01-17', nr_days_of_history=10):\n",
>>>>>>> many small improvements and more comments
=======
    "def create_stock_df(nr_days_to_trade=500, start_date_str='2017-01-17', nr_days_of_history=10):\n",
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
    "    \"\"\"\n",
    "    Wrapper for importing the stock data\n",
    "    \"\"\"\n",
    "\n",
    "    return(import_stock_data(nr_days_of_history, nr_days_to_trade, start_date_str))\n",
    "\n",
    "\n",
    "def calculateDates(nr_days_of_history, nr_days_to_trade, start_date_str):\n",
    "    \"\"\"\n",
    "    Calculates correct start and end dates for the data frame.\n",
    "    - The start date is moved backward in order to include the history_window for the first day of trading.\n",
    "    \"\"\"\n",
    "\n",
    "    # create a start date\n",
    "    start_date = pd.Timestamp(start_date_str)\n",
    "\n",
    "    # add end date\n",
    "    end_date = start_date + BDay(nr_days_to_trade)\n",
    "\n",
    "    # include a history window for first day\n",
    "    start_date = start_date - BDay(nr_days_of_history)\n",
    "\n",
    "    return {'start_date':start_date,'end_date':end_date}\n",
    "\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "def read_in_as_list_of_dfs(all_files,start_date,end_date):\n",
    "    \"\"\"\n",
    "    Create list of cleaned data frames of the stock data in the specified files\n",
    "    \"\"\"\n",
=======
    "# todo do proper check for file not found\n",
    "def import_stock_data(nr_days_of_history, nr_days_to_trade, start_date_str):\n",
=======
    "def read_in_as_list_of_dfs(all_files,start_date,end_date):\n",
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
    "    \"\"\"\n",
    "    Create list of cleaned data frames of the stock data in the specified files\n",
    "    \"\"\"\n",
<<<<<<< HEAD
    "    # OBS!!!!!! temporary limitation for the size of the data frame\n",
    "    size_of_subset = 100\n",
    "    \n",
    "    # pick out the desired start and end dates\n",
    "    dates = calculateDates(nr_days_of_history = nr_days_of_history, nr_days_to_trade = nr_days_to_trade, start_date_str = start_date_str)\n",
    "\n",
    "    # list the files to be read\n",
    "    path = \"./data/full_history/*.csv\"\n",
    "    all_files = np.array(glob.glob(path))\n",
    "\n",
>>>>>>> many small improvements and more comments
=======
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
    "    # create an empty list to add each (relevant) stock's data frame\n",
    "    li=[]\n",
    "\n",
    "    # go through all the files in the folder\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    for filename in all_files:\n",
=======
    "    for filename in all_files[:size_of_subset]:\n",
>>>>>>> many small improvements and more comments
=======
    "    for filename in all_files:\n",
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
    "        # read in the file\n",
    "        df = pd.read_csv(filename, parse_dates=[0])\n",
    "        \n",
    "        # basic trimming: drop all extra columns,rename the stock value column after the stock\n",
    "        df = df.drop(labels=list(['volume','close','high','low','adjclose']), axis='columns') \n",
    "        stock_name = filename.split(sep='/')[3].split(sep='.')[0].lower()\n",
    "        df = df.rename(columns={'open': stock_name})\n",
    "        \n",
    "        # fit to time window: selct only rows with relevant dates and ignore stocks without relevant values\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "        df = df.loc[(df['date'] > start_date) & (df['date'] < end_date)]\n",
    "        if df.empty:\n",
    "            continue\n",
    "        \n",
    "        # prepare to join on dates \n",
    "        df=df.set_index('date')\n",
    "\n",
    "        # remove duplicates\n",
    "        df = df.loc[np.logical_not(df.index.duplicated())]\n",
    "\n",
    "        # add to list of dfs\n",
    "        li.append(df)\n",
    "\n",
    "    return(li)\n",
    "\n",
    "\n",
    "def clean_combined_df(df):\n",
    "    \"\"\"\n",
    "    Reduce the size and time unnecessary info (date)\n",
    "    \"\"\"\n",
    "    # remove dates (anonymises the time window somewhat)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # set non-existing recordings to zero (stock had zero value at the time)\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    # select the smallest suitable type of float for the data\n",
    "    df = df.astype(np.float16)\n",
    "\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def import_stock_data(nr_days_of_history, nr_days_to_trade, start_date_str):\n",
    "    \"\"\"\n",
    "    Imports the relevant data from the text file system as a pandas data frame\n",
    "    \"\"\"\n",
    "    \n",
    "    # pick out the desired start and end dates\n",
    "    dates = calculateDates(nr_days_of_history = nr_days_of_history, nr_days_to_trade = nr_days_to_trade, start_date_str = start_date_str)\n",
    "\n",
    "    # list the files to be read\n",
    "    path = \"./data/full_history/*.csv\"\n",
    "    all_files = np.array(glob.glob(path))\n",
    "\n",
    "    # read in the data frames from the files\n",
    "    li = read_in_as_list_of_dfs(all_files, dates['start_date'], dates['end_date'])\n",
    "\n",
    "    # combine into a single data frame\n",
    "    df = pd.concat(li, join='outer', axis=1)\n",
    "\n",
    "    # clean the combined data frame\n",
    "    df = clean_combined_df(df)\n",
=======
    "        df = df.loc[(df['date'] > dates['start_date']) & (df['date'] < dates['end_date'])]\n",
=======
    "        df = df.loc[(df['date'] > start_date) & (df['date'] < end_date)]\n",
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
    "        if df.empty:\n",
    "            continue\n",
    "        \n",
    "        # prepare to join on dates \n",
    "        df=df.set_index('date')\n",
    "\n",
    "        # remove duplicates\n",
    "        df = df.loc[np.logical_not(df.index.duplicated())]\n",
    "\n",
    "        # add to list of dfs\n",
    "        li.append(df)\n",
    "\n",
    "    return(li)\n",
    "\n",
    "\n",
    "def clean_combined_df(df):\n",
    "    \"\"\"\n",
    "    Reduce the size and time unnecessary info (date)\n",
    "    \"\"\"\n",
    "    # remove dates (anonymises the time window somewhat)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # set non-existing recordings to zero (stock had zero value at the time)\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    # select the smallest suitable type of float for the data\n",
    "    df = df.astype(np.float16)\n",
    "\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def import_stock_data(nr_days_of_history, nr_days_to_trade, start_date_str):\n",
    "    \"\"\"\n",
    "    Imports the relevant data from the text file system as a pandas data frame\n",
    "    \"\"\"\n",
    "    \n",
    "    # pick out the desired start and end dates\n",
    "    dates = calculateDates(nr_days_of_history = nr_days_of_history, nr_days_to_trade = nr_days_to_trade, start_date_str = start_date_str)\n",
    "\n",
    "    # list the files to be read\n",
    "    path = \"./data/full_history/*.csv\"\n",
    "    all_files = np.array(glob.glob(path))\n",
    "\n",
    "    # read in the data frames from the files\n",
    "    li = read_in_as_list_of_dfs(all_files, dates['start_date'], dates['end_date'])\n",
    "\n",
    "    # combine into a single data frame\n",
    "    df = pd.concat(li, join='outer', axis=1)\n",
    "\n",
<<<<<<< HEAD
    "    # remove dates (anonymises the time window somewhat)\n",
    "    #df.reset_index(drop=True)\n",
>>>>>>> many small improvements and more comments
=======
    "    # clean the combined data frame\n",
    "    df = clean_combined_df(df)\n",
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
    "\n",
    "    return(df)\n",
    "\n",
    "#window = sys.argv[1]\n",
    "#start_date = sys.argv[2]\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "create_stock_df()\n"
=======
    "create_stock_df()"
>>>>>>> many small improvements and more comments
=======
    "create_stock_df()\n"
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
=======
    "create_stock_df()\n",
    " "
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#window = sys.argv[1]\n",
    "#start_date = sys.argv[2]\n",
    "df = create_stock_df()\n"
=======
   "execution_count": 13,
=======
   "execution_count": 128,
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "\n"
>>>>>>> many small improvements and more comments
=======
    "#window = sys.argv[1]\n",
    "#start_date = sys.argv[2]\n",
    "df = create_stock_df()\n"
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          sail        isd        men       dfnl       srf      cnacu  \\\n0     0.000000  15.507812  11.320312   0.000000  0.000000   0.000000   \n1     0.000000  15.562500  11.359375   0.000000  0.000000   0.000000   \n2     0.000000  15.492188  11.359375   0.000000  0.000000   0.000000   \n3     0.000000  15.609375  11.460938   0.000000  0.000000   0.000000   \n4     0.000000  15.640625  11.476562   0.000000  0.000000   0.000000   \n..         ...        ...        ...        ...       ...        ...   \n458  24.203125  13.578125   9.718750  22.734375  8.101562   0.000000   \n459  23.515625  13.539062   9.648438  22.375000  7.910156   0.000000   \n460  25.343750  13.562500   9.671875  22.906250  8.031250   0.000000   \n461  26.312500  13.523438   9.687500  23.093750  8.132812   0.000000   \n462  26.093750  13.609375   9.750000  23.312500  8.148438  12.992188   \n\n           hud       intg       fun      iusb  ...       botj       krnt  \\\n0    54.375000  29.406250  63.50000  50.28125  ...  15.203125  13.148438   \n1    53.781250  29.406250  63.78125  50.37500  ...  15.140625  12.648438   \n2    54.000000  28.000000  64.50000  50.31250  ...  15.023438  12.500000   \n3    55.468750  29.406250  64.75000  50.43750  ...  15.390625  12.750000   \n4    58.250000  29.343750  63.71875  50.43750  ...  15.453125  13.453125   \n..         ...        ...       ...       ...  ...        ...        ...   \n458  21.109375  30.656250  49.59375  48.75000  ...  14.656250  17.984375   \n459  20.312500  30.656250  52.56250  48.65625  ...  14.921875  17.625000   \n460  21.109375  30.656250  51.93750  48.59375  ...  14.882812  18.296875   \n461  21.156250  30.656250  51.53125  48.46875  ...  14.882812  18.593750   \n462  21.171875  29.265625  52.50000  48.43750  ...  14.859375  18.875000   \n\n           hk      kamn       fad         ua       asfi       eacq       tcx  \\\n0    9.101562  49.25000  52.87500  26.000000   9.953125   9.859375  36.93750   \n1    9.703125  51.09375  53.71875  26.453125  10.101562   9.859375  37.56250   \n2    9.671875  50.75000  53.68750  26.453125  10.046875   9.859375  38.15625   \n3    9.703125  50.34375  53.53125  27.468750  10.101562   9.851562  37.31250   \n4    9.828125  50.00000  53.53125  27.125000  10.148438   9.851562  38.00000   \n..        ...       ...       ...        ...        ...        ...       ...   \n458  3.390625  62.12500  67.06250  16.859375   3.750000  10.492188  52.28125   \n459  3.119141  61.62500  65.00000  19.843750   3.820312  10.468750  50.90625   \n460  3.300781  63.62500  67.25000  20.796875   3.810547  10.507812  50.62500   \n461  3.720703  63.78125  67.75000  19.828125   3.810547  10.242188  50.31250   \n462  3.830078  60.00000  68.75000  21.093750   3.849609  10.187500  50.37500   \n\n          rdnt  \n0     6.550781  \n1     6.449219  \n2     6.398438  \n3     6.250000  \n4     6.199219  \n..         ...  \n458  15.093750  \n459  15.039062  \n460  14.992188  \n461  14.796875  \n462  14.453125  \n\n[463 rows x 6014 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sail</th>\n      <th>isd</th>\n      <th>men</th>\n      <th>dfnl</th>\n      <th>srf</th>\n      <th>cnacu</th>\n      <th>hud</th>\n      <th>intg</th>\n      <th>fun</th>\n      <th>iusb</th>\n      <th>...</th>\n      <th>botj</th>\n      <th>krnt</th>\n      <th>hk</th>\n      <th>kamn</th>\n      <th>fad</th>\n      <th>ua</th>\n      <th>asfi</th>\n      <th>eacq</th>\n      <th>tcx</th>\n      <th>rdnt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>15.507812</td>\n      <td>11.320312</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>54.375000</td>\n      <td>29.406250</td>\n      <td>63.50000</td>\n      <td>50.28125</td>\n      <td>...</td>\n      <td>15.203125</td>\n      <td>13.148438</td>\n      <td>9.101562</td>\n      <td>49.25000</td>\n      <td>52.87500</td>\n      <td>26.000000</td>\n      <td>9.953125</td>\n      <td>9.859375</td>\n      <td>36.93750</td>\n      <td>6.550781</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>15.562500</td>\n      <td>11.359375</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>53.781250</td>\n      <td>29.406250</td>\n      <td>63.78125</td>\n      <td>50.37500</td>\n      <td>...</td>\n      <td>15.140625</td>\n      <td>12.648438</td>\n      <td>9.703125</td>\n      <td>51.09375</td>\n      <td>53.71875</td>\n      <td>26.453125</td>\n      <td>10.101562</td>\n      <td>9.859375</td>\n      <td>37.56250</td>\n      <td>6.449219</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>15.492188</td>\n      <td>11.359375</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>54.000000</td>\n      <td>28.000000</td>\n      <td>64.50000</td>\n      <td>50.31250</td>\n      <td>...</td>\n      <td>15.023438</td>\n      <td>12.500000</td>\n      <td>9.671875</td>\n      <td>50.75000</td>\n      <td>53.68750</td>\n      <td>26.453125</td>\n      <td>10.046875</td>\n      <td>9.859375</td>\n      <td>38.15625</td>\n      <td>6.398438</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>15.609375</td>\n      <td>11.460938</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>55.468750</td>\n      <td>29.406250</td>\n      <td>64.75000</td>\n      <td>50.43750</td>\n      <td>...</td>\n      <td>15.390625</td>\n      <td>12.750000</td>\n      <td>9.703125</td>\n      <td>50.34375</td>\n      <td>53.53125</td>\n      <td>27.468750</td>\n      <td>10.101562</td>\n      <td>9.851562</td>\n      <td>37.31250</td>\n      <td>6.250000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>15.640625</td>\n      <td>11.476562</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>58.250000</td>\n      <td>29.343750</td>\n      <td>63.71875</td>\n      <td>50.43750</td>\n      <td>...</td>\n      <td>15.453125</td>\n      <td>13.453125</td>\n      <td>9.828125</td>\n      <td>50.00000</td>\n      <td>53.53125</td>\n      <td>27.125000</td>\n      <td>10.148438</td>\n      <td>9.851562</td>\n      <td>38.00000</td>\n      <td>6.199219</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>458</th>\n      <td>24.203125</td>\n      <td>13.578125</td>\n      <td>9.718750</td>\n      <td>22.734375</td>\n      <td>8.101562</td>\n      <td>0.000000</td>\n      <td>21.109375</td>\n      <td>30.656250</td>\n      <td>49.59375</td>\n      <td>48.75000</td>\n      <td>...</td>\n      <td>14.656250</td>\n      <td>17.984375</td>\n      <td>3.390625</td>\n      <td>62.12500</td>\n      <td>67.06250</td>\n      <td>16.859375</td>\n      <td>3.750000</td>\n      <td>10.492188</td>\n      <td>52.28125</td>\n      <td>15.093750</td>\n    </tr>\n    <tr>\n      <th>459</th>\n      <td>23.515625</td>\n      <td>13.539062</td>\n      <td>9.648438</td>\n      <td>22.375000</td>\n      <td>7.910156</td>\n      <td>0.000000</td>\n      <td>20.312500</td>\n      <td>30.656250</td>\n      <td>52.56250</td>\n      <td>48.65625</td>\n      <td>...</td>\n      <td>14.921875</td>\n      <td>17.625000</td>\n      <td>3.119141</td>\n      <td>61.62500</td>\n      <td>65.00000</td>\n      <td>19.843750</td>\n      <td>3.820312</td>\n      <td>10.468750</td>\n      <td>50.90625</td>\n      <td>15.039062</td>\n    </tr>\n    <tr>\n      <th>460</th>\n      <td>25.343750</td>\n      <td>13.562500</td>\n      <td>9.671875</td>\n      <td>22.906250</td>\n      <td>8.031250</td>\n      <td>0.000000</td>\n      <td>21.109375</td>\n      <td>30.656250</td>\n      <td>51.93750</td>\n      <td>48.59375</td>\n      <td>...</td>\n      <td>14.882812</td>\n      <td>18.296875</td>\n      <td>3.300781</td>\n      <td>63.62500</td>\n      <td>67.25000</td>\n      <td>20.796875</td>\n      <td>3.810547</td>\n      <td>10.507812</td>\n      <td>50.62500</td>\n      <td>14.992188</td>\n    </tr>\n    <tr>\n      <th>461</th>\n      <td>26.312500</td>\n      <td>13.523438</td>\n      <td>9.687500</td>\n      <td>23.093750</td>\n      <td>8.132812</td>\n      <td>0.000000</td>\n      <td>21.156250</td>\n      <td>30.656250</td>\n      <td>51.53125</td>\n      <td>48.46875</td>\n      <td>...</td>\n      <td>14.882812</td>\n      <td>18.593750</td>\n      <td>3.720703</td>\n      <td>63.78125</td>\n      <td>67.75000</td>\n      <td>19.828125</td>\n      <td>3.810547</td>\n      <td>10.242188</td>\n      <td>50.31250</td>\n      <td>14.796875</td>\n    </tr>\n    <tr>\n      <th>462</th>\n      <td>26.093750</td>\n      <td>13.609375</td>\n      <td>9.750000</td>\n      <td>23.312500</td>\n      <td>8.148438</td>\n      <td>12.992188</td>\n      <td>21.171875</td>\n      <td>29.265625</td>\n      <td>52.50000</td>\n      <td>48.43750</td>\n      <td>...</td>\n      <td>14.859375</td>\n      <td>18.875000</td>\n      <td>3.830078</td>\n      <td>60.00000</td>\n      <td>68.75000</td>\n      <td>21.093750</td>\n      <td>3.849609</td>\n      <td>10.187500</td>\n      <td>50.37500</td>\n      <td>14.453125</td>\n    </tr>\n  </tbody>\n</table>\n<p>463 rows × 6014 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 129
=======
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-00cf07b74dcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
>>>>>>> many small improvements and more comments
=======
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          sail        isd        men       dfnl       srf      cnacu  \\\n0     0.000000  15.507812  11.320312   0.000000  0.000000   0.000000   \n1     0.000000  15.562500  11.359375   0.000000  0.000000   0.000000   \n2     0.000000  15.492188  11.359375   0.000000  0.000000   0.000000   \n3     0.000000  15.609375  11.460938   0.000000  0.000000   0.000000   \n4     0.000000  15.640625  11.476562   0.000000  0.000000   0.000000   \n..         ...        ...        ...        ...       ...        ...   \n458  24.203125  13.578125   9.718750  22.734375  8.101562   0.000000   \n459  23.515625  13.539062   9.648438  22.375000  7.910156   0.000000   \n460  25.343750  13.562500   9.671875  22.906250  8.031250   0.000000   \n461  26.312500  13.523438   9.687500  23.093750  8.132812   0.000000   \n462  26.093750  13.609375   9.750000  23.312500  8.148438  12.992188   \n\n           hud       intg       fun      iusb  ...       botj       krnt  \\\n0    54.375000  29.406250  63.50000  50.28125  ...  15.203125  13.148438   \n1    53.781250  29.406250  63.78125  50.37500  ...  15.140625  12.648438   \n2    54.000000  28.000000  64.50000  50.31250  ...  15.023438  12.500000   \n3    55.468750  29.406250  64.75000  50.43750  ...  15.390625  12.750000   \n4    58.250000  29.343750  63.71875  50.43750  ...  15.453125  13.453125   \n..         ...        ...       ...       ...  ...        ...        ...   \n458  21.109375  30.656250  49.59375  48.75000  ...  14.656250  17.984375   \n459  20.312500  30.656250  52.56250  48.65625  ...  14.921875  17.625000   \n460  21.109375  30.656250  51.93750  48.59375  ...  14.882812  18.296875   \n461  21.156250  30.656250  51.53125  48.46875  ...  14.882812  18.593750   \n462  21.171875  29.265625  52.50000  48.43750  ...  14.859375  18.875000   \n\n           hk      kamn       fad         ua       asfi       eacq       tcx  \\\n0    9.101562  49.25000  52.87500  26.000000   9.953125   9.859375  36.93750   \n1    9.703125  51.09375  53.71875  26.453125  10.101562   9.859375  37.56250   \n2    9.671875  50.75000  53.68750  26.453125  10.046875   9.859375  38.15625   \n3    9.703125  50.34375  53.53125  27.468750  10.101562   9.851562  37.31250   \n4    9.828125  50.00000  53.53125  27.125000  10.148438   9.851562  38.00000   \n..        ...       ...       ...        ...        ...        ...       ...   \n458  3.390625  62.12500  67.06250  16.859375   3.750000  10.492188  52.28125   \n459  3.119141  61.62500  65.00000  19.843750   3.820312  10.468750  50.90625   \n460  3.300781  63.62500  67.25000  20.796875   3.810547  10.507812  50.62500   \n461  3.720703  63.78125  67.75000  19.828125   3.810547  10.242188  50.31250   \n462  3.830078  60.00000  68.75000  21.093750   3.849609  10.187500  50.37500   \n\n          rdnt  \n0     6.550781  \n1     6.449219  \n2     6.398438  \n3     6.250000  \n4     6.199219  \n..         ...  \n458  15.093750  \n459  15.039062  \n460  14.992188  \n461  14.796875  \n462  14.453125  \n\n[463 rows x 6014 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sail</th>\n      <th>isd</th>\n      <th>men</th>\n      <th>dfnl</th>\n      <th>srf</th>\n      <th>cnacu</th>\n      <th>hud</th>\n      <th>intg</th>\n      <th>fun</th>\n      <th>iusb</th>\n      <th>...</th>\n      <th>botj</th>\n      <th>krnt</th>\n      <th>hk</th>\n      <th>kamn</th>\n      <th>fad</th>\n      <th>ua</th>\n      <th>asfi</th>\n      <th>eacq</th>\n      <th>tcx</th>\n      <th>rdnt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>15.507812</td>\n      <td>11.320312</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>54.375000</td>\n      <td>29.406250</td>\n      <td>63.50000</td>\n      <td>50.28125</td>\n      <td>...</td>\n      <td>15.203125</td>\n      <td>13.148438</td>\n      <td>9.101562</td>\n      <td>49.25000</td>\n      <td>52.87500</td>\n      <td>26.000000</td>\n      <td>9.953125</td>\n      <td>9.859375</td>\n      <td>36.93750</td>\n      <td>6.550781</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>15.562500</td>\n      <td>11.359375</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>53.781250</td>\n      <td>29.406250</td>\n      <td>63.78125</td>\n      <td>50.37500</td>\n      <td>...</td>\n      <td>15.140625</td>\n      <td>12.648438</td>\n      <td>9.703125</td>\n      <td>51.09375</td>\n      <td>53.71875</td>\n      <td>26.453125</td>\n      <td>10.101562</td>\n      <td>9.859375</td>\n      <td>37.56250</td>\n      <td>6.449219</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>15.492188</td>\n      <td>11.359375</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>54.000000</td>\n      <td>28.000000</td>\n      <td>64.50000</td>\n      <td>50.31250</td>\n      <td>...</td>\n      <td>15.023438</td>\n      <td>12.500000</td>\n      <td>9.671875</td>\n      <td>50.75000</td>\n      <td>53.68750</td>\n      <td>26.453125</td>\n      <td>10.046875</td>\n      <td>9.859375</td>\n      <td>38.15625</td>\n      <td>6.398438</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>15.609375</td>\n      <td>11.460938</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>55.468750</td>\n      <td>29.406250</td>\n      <td>64.75000</td>\n      <td>50.43750</td>\n      <td>...</td>\n      <td>15.390625</td>\n      <td>12.750000</td>\n      <td>9.703125</td>\n      <td>50.34375</td>\n      <td>53.53125</td>\n      <td>27.468750</td>\n      <td>10.101562</td>\n      <td>9.851562</td>\n      <td>37.31250</td>\n      <td>6.250000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>15.640625</td>\n      <td>11.476562</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>58.250000</td>\n      <td>29.343750</td>\n      <td>63.71875</td>\n      <td>50.43750</td>\n      <td>...</td>\n      <td>15.453125</td>\n      <td>13.453125</td>\n      <td>9.828125</td>\n      <td>50.00000</td>\n      <td>53.53125</td>\n      <td>27.125000</td>\n      <td>10.148438</td>\n      <td>9.851562</td>\n      <td>38.00000</td>\n      <td>6.199219</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>458</th>\n      <td>24.203125</td>\n      <td>13.578125</td>\n      <td>9.718750</td>\n      <td>22.734375</td>\n      <td>8.101562</td>\n      <td>0.000000</td>\n      <td>21.109375</td>\n      <td>30.656250</td>\n      <td>49.59375</td>\n      <td>48.75000</td>\n      <td>...</td>\n      <td>14.656250</td>\n      <td>17.984375</td>\n      <td>3.390625</td>\n      <td>62.12500</td>\n      <td>67.06250</td>\n      <td>16.859375</td>\n      <td>3.750000</td>\n      <td>10.492188</td>\n      <td>52.28125</td>\n      <td>15.093750</td>\n    </tr>\n    <tr>\n      <th>459</th>\n      <td>23.515625</td>\n      <td>13.539062</td>\n      <td>9.648438</td>\n      <td>22.375000</td>\n      <td>7.910156</td>\n      <td>0.000000</td>\n      <td>20.312500</td>\n      <td>30.656250</td>\n      <td>52.56250</td>\n      <td>48.65625</td>\n      <td>...</td>\n      <td>14.921875</td>\n      <td>17.625000</td>\n      <td>3.119141</td>\n      <td>61.62500</td>\n      <td>65.00000</td>\n      <td>19.843750</td>\n      <td>3.820312</td>\n      <td>10.468750</td>\n      <td>50.90625</td>\n      <td>15.039062</td>\n    </tr>\n    <tr>\n      <th>460</th>\n      <td>25.343750</td>\n      <td>13.562500</td>\n      <td>9.671875</td>\n      <td>22.906250</td>\n      <td>8.031250</td>\n      <td>0.000000</td>\n      <td>21.109375</td>\n      <td>30.656250</td>\n      <td>51.93750</td>\n      <td>48.59375</td>\n      <td>...</td>\n      <td>14.882812</td>\n      <td>18.296875</td>\n      <td>3.300781</td>\n      <td>63.62500</td>\n      <td>67.25000</td>\n      <td>20.796875</td>\n      <td>3.810547</td>\n      <td>10.507812</td>\n      <td>50.62500</td>\n      <td>14.992188</td>\n    </tr>\n    <tr>\n      <th>461</th>\n      <td>26.312500</td>\n      <td>13.523438</td>\n      <td>9.687500</td>\n      <td>23.093750</td>\n      <td>8.132812</td>\n      <td>0.000000</td>\n      <td>21.156250</td>\n      <td>30.656250</td>\n      <td>51.53125</td>\n      <td>48.46875</td>\n      <td>...</td>\n      <td>14.882812</td>\n      <td>18.593750</td>\n      <td>3.720703</td>\n      <td>63.78125</td>\n      <td>67.75000</td>\n      <td>19.828125</td>\n      <td>3.810547</td>\n      <td>10.242188</td>\n      <td>50.31250</td>\n      <td>14.796875</td>\n    </tr>\n    <tr>\n      <th>462</th>\n      <td>26.093750</td>\n      <td>13.609375</td>\n      <td>9.750000</td>\n      <td>23.312500</td>\n      <td>8.148438</td>\n      <td>12.992188</td>\n      <td>21.171875</td>\n      <td>29.265625</td>\n      <td>52.50000</td>\n      <td>48.43750</td>\n      <td>...</td>\n      <td>14.859375</td>\n      <td>18.875000</td>\n      <td>3.830078</td>\n      <td>60.00000</td>\n      <td>68.75000</td>\n      <td>21.093750</td>\n      <td>3.849609</td>\n      <td>10.187500</td>\n      <td>50.37500</td>\n      <td>14.453125</td>\n    </tr>\n  </tbody>\n</table>\n<p>463 rows × 6014 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 129
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
    }
   ],
   "source": [
    "df"
   ]
<<<<<<< HEAD
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> many small improvements and more comments
=======
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
<<<<<<< HEAD
   "version": "3.8.2-final"
=======
   "version": "3.6.9-final"
>>>>>>> many small improvements and more comments
=======
   "version": "3.8.2-final"
>>>>>>> improved data cleaning: fixed bug in data (duplicates) and reduced the size of the total date frame
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}